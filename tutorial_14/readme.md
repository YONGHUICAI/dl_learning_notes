# 卷积神经网络 训练MNIST数据集

- softmax逻辑回归训练，准确率 90%
- 神经网络训练 + 激活函数sigmoid 准确率95%
- 卷积神经网络训练 + relu + 池化, 全连接层 + dropout. 最终准确率达到98.6%

### 小结
- 如果加大训练层数，学习率就要降低
- mnist数据集可以预先下载，因为有时候网络不通
- 激活函数选择很重要！
- 学习方法，使用梯度下降还是Ada等有不同的学习率与损失率

### 关于CNN
- 卷积层，最重要的是步长，卷积大小，featuremap的个数
- relu层，激活函数功能
- 池化层，特征提取，均值池化与最大池化，步长与窗口大小一致
- 全连接层，把深度图像转换为像素节点输出
- dropout 对全连接层做调整
- 输出层 输出最终结果